# Craft #2: Distributed Message Queue

**Component:** Kafka-like message queue with partitioning, consumer groups, and coordination
**Learning Goal:** Build a message queue from first principles, then understand why distributed systems need consensus
**Total Time:** 8-12 hours across 3 phases
**Target Performance:** 1M+ messages/sec, horizontal scaling, automatic failover

---

## Overview

Craft #2 teaches you how to build a production-grade message queue through **progressive abstraction**. You'll start with file-based partitioning (single machine), add multi-process coordination, then finally implement distributed consensus across machines.

**Key Learning:** Understand partitioning, offsets, consumer groups, and rebalancing before using Kafka in production.

---

## Architecture Evolution

### Starting Point (Craft #1)
```
Ingestion Service ‚Üí writes directly to metrics.jsonl file
```
- **Problem:** Tight coupling between ingestion and storage
- **Limitation:** Can't scale processing independently

### Phase 1: Partitioned Queue
```
Ingestion ‚Üí [Partitioned Queue] ‚Üí Consumer
              partition-0/
              partition-1/          (file-based, single machine)
              partition-2/
              partition-3/
```
- **Benefit:** Decoupled ingestion from processing
- **Limitation:** Single consumer, no fault tolerance

### Phase 2: Consumer Groups
```
Ingestion ‚Üí [Queue] ‚Üí Consumer Group
                       ‚îú‚îÄ Consumer A (P0, P2)
                       ‚îî‚îÄ Consumer B (P1, P3)
```
- **Benefit:** Parallel processing, automatic rebalancing
- **Limitation:** Single machine only (file-based coordination)

### Phase 3: Distributed Coordination
```
Ingestion ‚Üí [Queue] ‚Üí Consumer Group (multi-machine)
   ‚îÇ           ‚îÇ       ‚îú‚îÄ Consumer A @ node-1
   ‚îÇ           ‚îÇ       ‚îú‚îÄ Consumer B @ node-2
   ‚îÇ           ‚îÇ       ‚îî‚îÄ Consumer C @ node-3
   ‚îÇ           ‚îÇ
   ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ ZooKeeper (coordination)
   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Multiple brokers with replication
```
- **Benefit:** Network-wide coordination, true fault tolerance
- **Scalability:** Horizontal scaling across data centers

---

## Phase Breakdown

### Phase 1: File-Based Partitioned Queue ‚úÖ

**Documentation:** [phase-1-partitioned-queue/design.md](phase-1-partitioned-queue/design.md)

**Goal:** Understand message queue fundamentals - partitioning, offsets, producer/consumer patterns

**Time:** 3-4 hours
**Status:** ‚úÖ **COMPLETE** (Phase 9 in main branch)

**Implementation:**
- File-based partitioned queue (`include/partitioned_queue.h`, `src/partitioned_queue.cpp`)
- 4 partitions with hash-based routing (client_id ‚Üí partition)
- Sequential offset management per partition
- Producer: `enqueue(client_id, data)` writes to `queue/partition-N/OFFSET.msg`
- Consumer: `QueueConsumer` reads from partitions with offset tracking

**Performance:**
- **Throughput:** ~800 RPS (measured with concurrent load test)
- **Latency:** ~0.70ms avg (file I/O)
- **Success Rate:** 98.7% @ concurrent load
- **Limitation:** Single machine only, disk I/O bound

**Key Learning:** File-based queues are simple, durable, and reliable. At this scale, file I/O sequencing is the primary bottleneck for throughput, not individual latency.

---

### Phase 2: Kafka Integration ‚úÖ

**Documentation:**
- [Craft #2, Phase 2 Worktree](../.worktrees/craft-2-phase-11-kafka/)
- [PHASE_11_KAFKA_INTEGRATION.md](../.worktrees/craft-2-phase-11-kafka/PHASE_11_KAFKA_INTEGRATION.md)
- [Kafka Threading Fix Documentation](../docs/kafka-fix/OVERVIEW.md)

**Goal:** Compare file-based queue with production-grade Kafka - understand what Kafka optimizes for

**Time:** 4-6 hours
**Status:** ‚úÖ **COMPLETE** (Committed Nov 2, 2025)

**Implementation:**
- Kafka producer integration (`include/kafka_producer.h`, `src/kafka_producer.cpp`)
- Kafka consumer with consumer groups (`include/kafka_consumer.h`, `src/kafka_consumer.cpp`)
- Dual-mode architecture: runtime switch between file-based OR Kafka (`QueueMode` enum)
- Fixed 4 critical threading bugs:
  1. Race condition (no mutex on shared KafkaProducer)
  2. Use-after-free in destructor (messages in-flight during shutdown)
  3. No retry logic for queue full errors
  4. Message lifetime issues with async sends

**Performance:**
- **Throughput:** 100,000+ RPS (verified under concurrent load)
- **Latency:** ~0.15ms avg (same as file-based, network overhead negligible)
- **Success Rate:** 97.9% @ concurrent load
- **Scalability:** Horizontally scales across machines with proper infrastructure

**Key Learning:** Kafka delivers 125x throughput improvement over file-based queues. The latency is similar because network latency to local Kafka is minimal. Kafka's power comes from batching, replication, and horizontal scaling - not from raw latency improvements.

**Comparison Results (Phase 11 Verified):**
```
Mode        | RPS         | Latency | Success | Key Benefit
------------|-------------|---------|---------|---------------------------------------
File-based  | 800         | 0.70ms  | 98.7%   | Simple, durable, single-machine
Kafka       | 100,000+    | 0.15ms  | 97.9%   | 125x throughput! Distributed, scalable
```

**Threading Insights:**
- librdkafka is NOT thread-safe - requires external mutex
- 16 HTTP worker threads ‚Üí 1 shared KafkaProducer ‚Üí 1 background I/O thread
- Defense in depth: flush(10s) + poll() loop + warnings
- Always handle ERR__QUEUE_FULL with retry logic

---

### Phase 3: Distributed Coordination üìù

**Documentation:** *(to be created)*

**Goal:** Scale beyond single machine using ZooKeeper/Raft for distributed consensus

**Time:** 4-5 hours
**Status:** üìù Planned

---

## Related Documentation

- **[Phases to Crafts Mapping](../docs/PHASES_TO_CRAFTS_MAPPING.md)** - Full Craft #2 details
- **[Phase 1 Design](phase-1-partitioned-queue/design.md)** - File-based queue architecture
- **[Phase 2 Design](phase-2-consumer-coordination/design.md)** - Consumer group coordination
- **[Craft #1 README](../craft1/README.md)** - Ingestion service (producer)

---

**This is Craft #2 of Systems Craft.** Once complete, you'll understand how Kafka, Pulsar, and RabbitMQ work internally.
